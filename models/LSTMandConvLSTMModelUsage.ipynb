{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tensorflow import keras\n",
    "from models import CLSTM_classifier, LSTM_classifier\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import History \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_data = pd.read_csv(\"../data/denver_series_data.csv\")\n",
    "X_variables = [\"humidity_Denver\",\"pressure_Denver\",\"temperature_Denver\",\"wind_direction_Denver\",\"wind_speed_Denver\"]\n",
    "y_variables = [\"weather_description_Denver\"]\n",
    "\n",
    "X_data = series_data[X_variables]\n",
    "y_data = series_data[y_variables]\n",
    "\n",
    "number_of_hours_to_predict = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_X_data = X_data.loc[X_data[\"temperature_Denver\"] != 0]\n",
    "min_X_data = non_zero_X_data.min()\n",
    "max_X_data = non_zero_X_data.max()\n",
    "\n",
    "normalized_X_data = (X_data - min_X_data) / (max_X_data - min_X_data) \n",
    "normalized_X_data = pd.concat([normalized_X_data, y_data], axis=1)\n",
    "normalized_X_data = normalized_X_data.clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge similar weather types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_similar(data, similarities, new_value):\n",
    "    for similarity in similarities:\n",
    "        data.loc[data[\"weather_description_Denver\"] == similarity] = new_value\n",
    "    return data\n",
    "    \n",
    "light_rain = [3, 16, 19, 22, 23, 30, 32, 33]\n",
    "mist = [13]\n",
    "haze = [24, 26, 7]\n",
    "snow = [9, 31]\n",
    "moderate_rain = [12, 17, 18, 20, 25, 27, 28, 29, 34]\n",
    "\n",
    "y_data = merge_similar(y_data, light_rain, 1)\n",
    "y_data = merge_similar(y_data, mist, 10)\n",
    "y_data = merge_similar(y_data, haze, 11)\n",
    "y_data = merge_similar(y_data, snow, 15)\n",
    "y_data = merge_similar(y_data, moderate_rain, 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate All Possible Sequences for LSTM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_arrays = []\n",
    "y_data_arrays = []\n",
    "\n",
    "for index in series_data.loc[series_data[\"weather_description_Denver\"] != 0].index:\n",
    "    if index >= 24 and index < series_data.shape[0]:\n",
    "        X_data_arrays.append(normalized_X_data.iloc[index - 24: index][X_variables + y_variables].values)\n",
    "        y_data_arrays.append(y_data.iloc[index: index+number_of_hours_to_predict][y_variables].values)\n",
    "        \n",
    "X_data_arrays = np.array(X_data_arrays)\n",
    "y_data_arrays = np.array(y_data_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Y Targets to Categorical 1-Hot Encoded Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezed_y_data = np.squeeze(y_data_arrays, axis=1)\n",
    "\n",
    "def transform_labels_0_n(y_data):\n",
    "    label = 0\n",
    "    labels = {}\n",
    "    \n",
    "    for i, target in enumerate(y_data):\n",
    "        if target[0] not in labels:\n",
    "            labels[target[0]] = label\n",
    "            label += 1\n",
    "            \n",
    "        y_data[i][0] = labels[target[0]]\n",
    "                                     \n",
    "    return y_data\n",
    "\n",
    "transformed_y_data = transform_labels_0_n(squeezed_y_data)\n",
    "categorical_y_data = to_categorical(squeezed_y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data Into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data_arrays, categorical_y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=30\n",
    "batch_size = 500\n",
    "sequence_size = 24\n",
    "inputs = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, 24, 6)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 24, 128)           69120     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "OutputLayer (Dense)          (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 268,043\n",
      "Trainable params: 268,043\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history = History()\n",
    "model = LSTM_classifier(sequence_size,inputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "34558/34558 [==============================] - 8s 232us/step - loss: 1.7001 - acc: 0.4349\n",
      "Epoch 2/30\n",
      "34558/34558 [==============================] - 6s 167us/step - loss: 1.3413 - acc: 0.5603\n",
      "Epoch 3/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 1.2386 - acc: 0.5960\n",
      "Epoch 4/30\n",
      "34558/34558 [==============================] - 6s 165us/step - loss: 1.1748 - acc: 0.6223\n",
      "Epoch 5/30\n",
      "34558/34558 [==============================] - 6s 163us/step - loss: 1.1294 - acc: 0.6399\n",
      "Epoch 6/30\n",
      "34558/34558 [==============================] - 6s 165us/step - loss: 1.0939 - acc: 0.6530\n",
      "Epoch 7/30\n",
      "34558/34558 [==============================] - 6s 165us/step - loss: 1.0734 - acc: 0.6595\n",
      "Epoch 8/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 1.0509 - acc: 0.6698\n",
      "Epoch 9/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 1.0407 - acc: 0.6718\n",
      "Epoch 10/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 1.0236 - acc: 0.6765\n",
      "Epoch 11/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 1.0176 - acc: 0.6763\n",
      "Epoch 12/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 1.0087 - acc: 0.6822\n",
      "Epoch 13/30\n",
      "34558/34558 [==============================] - 6s 165us/step - loss: 0.9971 - acc: 0.6826\n",
      "Epoch 14/30\n",
      "34558/34558 [==============================] - 6s 165us/step - loss: 0.9986 - acc: 0.6825\n",
      "Epoch 15/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 0.9846 - acc: 0.6852\n",
      "Epoch 16/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 0.9769 - acc: 0.6888\n",
      "Epoch 17/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 0.9666 - acc: 0.6907\n",
      "Epoch 18/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 0.9633 - acc: 0.6903\n",
      "Epoch 19/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 0.9577 - acc: 0.6919\n",
      "Epoch 20/30\n",
      "34558/34558 [==============================] - 6s 165us/step - loss: 0.9492 - acc: 0.6923\n",
      "Epoch 21/30\n",
      "34558/34558 [==============================] - 6s 165us/step - loss: 0.9428 - acc: 0.6973\n",
      "Epoch 22/30\n",
      "34558/34558 [==============================] - 6s 165us/step - loss: 0.9348 - acc: 0.6959\n",
      "Epoch 23/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 0.9247 - acc: 0.6989\n",
      "Epoch 24/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 0.9177 - acc: 0.6982\n",
      "Epoch 25/30\n",
      "34558/34558 [==============================] - 6s 165us/step - loss: 0.9072 - acc: 0.7035\n",
      "Epoch 26/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 0.8995 - acc: 0.7057\n",
      "Epoch 27/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 0.8918 - acc: 0.7085\n",
      "Epoch 28/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 0.8746 - acc: 0.7116\n",
      "Epoch 29/30\n",
      "34558/34558 [==============================] - 6s 165us/step - loss: 0.8667 - acc: 0.7124\n",
      "Epoch 30/30\n",
      "34558/34558 [==============================] - 6s 164us/step - loss: 0.8601 - acc: 0.7141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f97674def60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[history])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "n_folds = 5\n",
    "cross_val = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "lstm_evaluations = []\n",
    "for train_index, test_index in cross_val.split(X_data_arrays[:,0]):\n",
    "    x_train = X_data_arrays[train_index]\n",
    "\n",
    "    y_train = categorical_y_data[train_index]\n",
    "    \n",
    "    x_test = X_data_arrays[test_index]\n",
    "    y_test = categorical_y_data[test_index]\n",
    "    \n",
    "    model = LSTM_classifier(sequence_size, inputs)\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test))\n",
    "\n",
    "    lstm_evaluations.append(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CLSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 22, 128)           2432      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 22, 128)           131584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "OutputLayer (Dense)          (None, 11)                2827      \n",
      "=================================================================\n",
      "Total params: 367,243\n",
      "Trainable params: 367,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history2 = History()\n",
    "model2 = CLSTM_classifier(sequence_size, inputs)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "34558/34558 [==============================] - 7s 197us/step - loss: 1.8515 - acc: 0.3841\n",
      "Epoch 2/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 1.3481 - acc: 0.5658\n",
      "Epoch 3/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 1.2194 - acc: 0.6287\n",
      "Epoch 4/30\n",
      "34558/34558 [==============================] - 5s 139us/step - loss: 1.1696 - acc: 0.6465\n",
      "Epoch 5/30\n",
      "34558/34558 [==============================] - 5s 141us/step - loss: 1.1450 - acc: 0.6535\n",
      "Epoch 6/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 1.1139 - acc: 0.6619\n",
      "Epoch 7/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 1.0944 - acc: 0.6675\n",
      "Epoch 8/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 1.0858 - acc: 0.6681\n",
      "Epoch 9/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 1.0691 - acc: 0.6728\n",
      "Epoch 10/30\n",
      "34558/34558 [==============================] - 5s 141us/step - loss: 1.0532 - acc: 0.6759\n",
      "Epoch 11/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 1.0449 - acc: 0.6756\n",
      "Epoch 12/30\n",
      "34558/34558 [==============================] - 5s 141us/step - loss: 1.0335 - acc: 0.6806\n",
      "Epoch 13/30\n",
      "34558/34558 [==============================] - 5s 141us/step - loss: 1.0297 - acc: 0.6807\n",
      "Epoch 14/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 1.0244 - acc: 0.6813\n",
      "Epoch 15/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 1.0081 - acc: 0.6834\n",
      "Epoch 16/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 1.0033 - acc: 0.6864\n",
      "Epoch 17/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 0.9957 - acc: 0.6847\n",
      "Epoch 18/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 0.9873 - acc: 0.6877\n",
      "Epoch 19/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 0.9819 - acc: 0.6908\n",
      "Epoch 20/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 0.9746 - acc: 0.6913\n",
      "Epoch 21/30\n",
      "34558/34558 [==============================] - 5s 141us/step - loss: 0.9672 - acc: 0.6923\n",
      "Epoch 22/30\n",
      "34558/34558 [==============================] - 5s 141us/step - loss: 0.9611 - acc: 0.6940\n",
      "Epoch 23/30\n",
      "34558/34558 [==============================] - 5s 143us/step - loss: 0.9592 - acc: 0.6935\n",
      "Epoch 24/30\n",
      "34558/34558 [==============================] - 5s 141us/step - loss: 0.9555 - acc: 0.6936\n",
      "Epoch 25/30\n",
      "34558/34558 [==============================] - 5s 141us/step - loss: 0.9428 - acc: 0.6963\n",
      "Epoch 26/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 0.9311 - acc: 0.7004\n",
      "Epoch 27/30\n",
      "34558/34558 [==============================] - 5s 141us/step - loss: 0.9304 - acc: 0.7004\n",
      "Epoch 28/30\n",
      "34558/34558 [==============================] - 5s 140us/step - loss: 0.9216 - acc: 0.7033\n",
      "Epoch 29/30\n",
      "34558/34558 [==============================] - 5s 141us/step - loss: 0.9195 - acc: 0.7028\n",
      "Epoch 30/30\n",
      "34558/34558 [==============================] - 5s 141us/step - loss: 0.9078 - acc: 0.7064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f975c073198>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=[history2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation CLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "n_folds = 5\n",
    "cross_val = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "clstm_evaluations = []\n",
    "for train_index, test_index in cross_val.split(X_data_arrays[:,0]):\n",
    "    x_train = X_data_arrays[train_index]\n",
    "\n",
    "    y_train = categorical_y_data[train_index]\n",
    "    \n",
    "    x_test = X_data_arrays[test_index]\n",
    "    y_test = categorical_y_data[test_index]\n",
    "    \n",
    "    model = CLSTM_classifier(sequence_size, inputs)\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test,y_test))\n",
    "\n",
    "    clstm_evaluations.append(model.evaluate(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
